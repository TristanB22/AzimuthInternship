{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456a46cc-3687-47d1-8891-5e688fa3949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size1: (187, 248, 4)\n",
      "Size2: (187, 248, 4)\n",
      "Size3: (187, 248, 4)\n",
      "(436, 17, 15, 4)\n",
      "x sect # is 16 and y sect # is 21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "\n",
    "img1 = plt.imread(\"/Users/tristanbrigham/GithubProjects/AzimuthInternship/DrLuckingProjects/STMProject1/firstSTM.png\")\n",
    "img2 = plt.imread(\"/Users/tristanbrigham/GithubProjects/AzimuthInternship/DrLuckingProjects/STMProject1/image2.png\")\n",
    "img3 = plt.imread(\"/Users/tristanbrigham/GithubProjects/AzimuthInternship/DrLuckingProjects/STMProject1/image3.png\")\n",
    "\n",
    "img2 = cv.resize(img2, dsize=(img1.shape[1], img1.shape[0]), interpolation=cv.INTER_NEAREST)\n",
    "img3 = cv.resize(img3, dsize=(img1.shape[1], img1.shape[0]), interpolation=cv.INTER_NEAREST)\n",
    "\n",
    "print(\"Size1: {}\".format(img1.shape))\n",
    "print(\"Size2: {}\".format(img2.shape))\n",
    "print(\"Size3: {}\".format(img3.shape))\n",
    "\n",
    "finalArray = np.zeros((436, 17, 15, 4))\n",
    "# finalArray2 = np.zeros((336, 17, 15, 4))\n",
    "# finalArray3 = np.zeros((336, 17, 15, 4))\n",
    "\n",
    "img2Array = np.zeros((336, 17, 15, 4))\n",
    "img3Array = np.zeros((336, 17, 15, 4))\n",
    "\n",
    "yAmt = int(img1.shape[1] /  14)\n",
    "offsetY = int(yAmt / 2)\n",
    "\n",
    "xAmt = int(img1.shape[0] / 12)\n",
    "# offsetX = int(xAmt / 2)\n",
    "offsetX = xAmt     #uncomment the above line and comment this one to add overlap\n",
    "\n",
    "count = 0\n",
    "x = xAmt\n",
    "\n",
    "possibleResults = [0, 1]\n",
    "\n",
    "while x < img1.shape[1]:\n",
    "    y = yAmt\n",
    "    while y < img1.shape[0] - offsetY:\n",
    "        imgTemp1 = img1[y - yAmt:y, x - xAmt:x]\n",
    "        finalArray[count] = imgTemp1\n",
    "        \n",
    "        imgTemp2 = img2[y - yAmt:y, x - xAmt:x]\n",
    "        img2Array[count] = imgTemp2\n",
    "\n",
    "        imgTemp3 = img3[y - yAmt:y, x - xAmt:x]\n",
    "        img3Array[count] = imgTemp3\n",
    "        count += 1\n",
    "        y += offsetY\n",
    "        if(count > 1000):\n",
    "            exit()\n",
    "    x += offsetX\n",
    "# \n",
    "# finalArray[336: 672] = finalArray2\n",
    "# finalArray[672: 1008] = finalArray3\n",
    "\n",
    "# count = 0\n",
    "# for img in finalArray[:1008]:\n",
    "#     cv.imwrite(\"Img{}.png\".format(count), img)\n",
    "#     count += 1\n",
    "    \n",
    "print(finalArray.shape)\n",
    "\n",
    "imagesWithDefectsNumbers = [23, 24, 25, 179, 199, 200, 201, 221, 222, 223]\n",
    "imagesWithDefects = np.zeros((10, 17, 15, 4))\n",
    "\n",
    "# labels = np.zeros((1108)) #going to be a zero if there is no defect\n",
    "# labels[1008 : 1109] = np.ones((100))\n",
    "\n",
    "labels = np.zeros((436))\n",
    "labels[336: 436] = np.ones((100))\n",
    "\n",
    "count = 0\n",
    "for i in imagesWithDefectsNumbers:\n",
    "    labels[i] = 1\n",
    "    imagesWithDefects[count] = finalArray[i]\n",
    "    count += 1\n",
    "\n",
    "for i in range(10):\n",
    "    # finalArray[1008 + (i * 10) : 1018 + (i * 10)] = imagesWithDefects[0 : 10]\n",
    "    finalArray[336 + (i * 10) : 346 + (i * 10)] = imagesWithDefects[0 : 10]\n",
    "\n",
    "xSections = int(img1.shape[1]/finalArray.shape[2])\n",
    "ySections = int(336/xSections) #using 336 because count is wonky -- should be final Array y shape\n",
    "\n",
    "print(\"x sect # is {} and y sect # is {}\".format(xSections, ySections))\n",
    "# 21 sections in y direction\n",
    "# 16 sections in x direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df9521-e8fc-4930-ba78-0d01b0c77637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "14/14 [==============================] - 5s 161ms/step - loss: 0.6255 - accuracy: 0.7339 - val_loss: 1.1451 - val_accuracy: 0.2647\n",
      "Epoch 2/35\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.6426 - accuracy: 0.7454 - val_loss: 0.8294 - val_accuracy: 0.2647\n",
      "Epoch 3/35\n",
      "14/14 [==============================] - 2s 106ms/step - loss: 0.6256 - accuracy: 0.7729 - val_loss: 0.9189 - val_accuracy: 0.3382\n",
      "Epoch 4/35\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.3917 - accuracy: 0.8303 - val_loss: 0.9559 - val_accuracy: 0.5588\n",
      "Epoch 5/35\n",
      " 9/14 [==================>...........] - ETA: 0s - loss: 0.3388 - accuracy: 0.8299"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "model = keras.models.Sequential([\n",
    "    #first layer is 64 7x7 filters\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[17, 15, 4]),\n",
    "    # pool reduce each spatial dimension by factor of 2\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    #Repeat 2 convolution layers followed by one pool twice\n",
    "    #number of filters increases as go further along\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    #need to flatten input for dense layer because need 1D array for input\n",
    "    keras.layers.Flatten(),\n",
    "    #Fully connected network, dropout layer to reduce overfit\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=2, activation='softmax'),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(finalArray, labels, epochs=35, validation_data=(finalArray[300:, :, :, :], labels[300:]))\n",
    "score = model.evaluate(finalArray[325:, :, :, :], labels[325:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b42e83-f350-421b-adc1-5ff61675d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: {}\".format(score[0]['accuracy']))\n",
    "X_new = finalArray # pretend we have new images\n",
    "y_pred = model.predict(X_new)\n",
    "for i in range(436):\n",
    "    pred = y_pred[i]\n",
    "    if possibleResults[pred.argmax()] != labels[i]:\n",
    "        print(\"Validation Image {} was incorrect :: {}\".format(i, labels[count]))\n",
    "\n",
    "newPred2 = model.predict(img2Array)\n",
    "count = -1\n",
    "defective2 = []\n",
    "nonDefective2 = []\n",
    "for pred in newPred2:\n",
    "    count += 1\n",
    "    if possibleResults[pred.argmax()] == 1:\n",
    "        defective2.append(count)\n",
    "        x = 15 * int(count / ySections) + xAmt\n",
    "        y = 17 * (count % ySections) + yAmt\n",
    "        cv.rectangle(img2, (x - xAmt, y - yAmt), (x, y), (0, 255, 0))\n",
    "    else:\n",
    "        nonDefective2.append(count)\n",
    "\n",
    "print(\"2:\\nDEFECTIVE: {} \\n\\nNONDEFECTIVE: {}\\n\\n\".format(defective2, nonDefective2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eabed4-2f4f-444c-a6e5-308336c3ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPred3 = model.predict(img3Array)\n",
    "count = 0\n",
    "defective3 = []\n",
    "nonDefective3 = []\n",
    "for pred in newPred3:\n",
    "    if possibleResults[pred.argmax()] == 1:\n",
    "        defective3.append(count) \n",
    "        x = 15 * int(count / ySections) + xAmt\n",
    "        y = 17 * (count % ySections) + yAmt\n",
    "        cv.rectangle(img3, (x - xAmt, y - yAmt), (x, y), (0, 255, 0))\n",
    "    else:\n",
    "        nonDefective3.append(count)\n",
    "    count += 1\n",
    "\n",
    "print(\"3:\\nDEFECTIVE: {} \\n\\nNONDEFECTIVE: {}\\n\\n\".format(defective3, nonDefective3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bc425-1d0a-4991-a116-a0e10640fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4\n",
    "\n",
    "img2 = cv.resize(img2, dsize=(img1.shape[1]*factor, img1.shape[0]*factor), interpolation=cv.INTER_NEAREST)\n",
    "img3 = cv.resize(img3, dsize=(img1.shape[1]*factor, img1.shape[0]*factor), interpolation=cv.INTER_NEAREST)\n",
    "\n",
    "cv.imshow(\"Img2 Bounded\", img2)\n",
    "cv.imshow(\"Img3 Bounded\", img3)\n",
    "if cv.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd782c-2e2e-43dd-b8e3-f692d928096c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
