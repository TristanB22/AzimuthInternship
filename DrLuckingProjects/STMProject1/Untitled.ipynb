{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456a46cc-3687-47d1-8891-5e688fa3949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (187, 248, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "\n",
    "img = plt.imread(\"/Users/tristanbrigham/GithubProjects/AzimuthInternship/DrLuckingProjects/STMProject1/firstSTM.png\")\n",
    "print(\"Size: {}\".format(img.shape))\n",
    "\n",
    "finalArray = np.zeros((336, 17, 15, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2df9521-e8fc-4930-ba78-0d01b0c77637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 17, 15, 4)\n"
     ]
    }
   ],
   "source": [
    "yAmt = int(img.shape[1] /  14)\n",
    "offsetY = int(yAmt / 2)\n",
    "\n",
    "xAmt = int(img.shape[0] / 12)\n",
    "# offsetX = int(xAmt / 2)\n",
    "offsetX = xAmt     #uncomment the above line and comment this one to add overlap\n",
    "\n",
    "count = 0\n",
    "x = xAmt\n",
    "\n",
    "possibleResults = [0, 1]\n",
    "\n",
    "while x < img.shape[1]:\n",
    "    y = yAmt\n",
    "    while y < img.shape[0] - offsetY:\n",
    "        imgTemp = img[y - yAmt:y, x - xAmt:x]\n",
    "        finalArray[count] = imgTemp\n",
    "        count += 1\n",
    "        y += offsetY\n",
    "        if(count > 1000):\n",
    "            exit()\n",
    "    x += offsetX\n",
    "    \n",
    "print(finalArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5b42e83-f350-421b-adc1-5ff61675d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesWithDefects = [23, 24, 25, 179, 199, 200, 201, 221, 222, 223]\n",
    "labels = np.zeros((336)) #going to be a zero if there is no defect\n",
    "\n",
    "for i in imagesWithDefects:\n",
    "    labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1aaf38b-8432-431f-bc01-916ebe871a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73c942-9f74-45ab-ab5b-9db1a6ca5f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bcfa9bf-63d0-4180-b02c-1a29778bfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "model = keras.models.Sequential([\n",
    "    #first layer is 64 7x7 filters\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[17, 15, 4]),\n",
    "    # pool reduce each spatial dimension by factor of 2\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    #Repeat 2 convolution layers followed by one pool twice\n",
    "    #number of filters increases as go further along\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    #need to flatten input for dense layer because need 1D array for input\n",
    "    keras.layers.Flatten(),\n",
    "    #Fully connected network, dropout layer to reduce overfit\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b2a39a7-c407-457a-9f9b-0de4fda1a8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21f43a23-e739-4cae-aebd-addd0c388564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.2239 - accuracy: 0.9446 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 2/4\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.1522 - accuracy: 0.9692 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 3/4\n",
      "11/11 [==============================] - 1s 97ms/step - loss: 0.1378 - accuracy: 0.9692 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 4/4\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.1148 - accuracy: 0.9692 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(finalArray[:325, :, :, :], labels[:325], epochs=4, validation_data=(finalArray[325:, :, :, :], labels[325:]))\n",
    "score = model.evaluate(finalArray[325:, :, :, :], labels[325:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24d522df-d76d-4f3f-8579-13be0c51bc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9c00173-bcca-486d-bb4a-f6274d842fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: {}\".format(score[0]['accuracy']))\n",
    "X_new = finalArray[:10] # pretend we have new images\n",
    "y_pred = model.predict(X_new)\n",
    "count = 0\n",
    "for pred in y_pred:\n",
    "    if possibleResults[pred.argmax()] != labels[count]:\n",
    "        print(\"Image {} was incorrect\".format(count))\n",
    "        plt.imshow(finalArray[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af7e2e-2d71-4570-82f4-0fb8c771e342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
